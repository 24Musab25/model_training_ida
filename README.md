# Synthetic-Data-Generation-and-Model-Training
this repository generates synthetic datas for model training, creates synthetic variances for model training. Real-world data and Synthetic data usage is more beneficial for model training.
blender.py script imports the  object files in glb format into the blender interface. Then rotates, resizes and pozes the objects randomly. Also, adds random camera position and light. Finally, takes the final object's screenshot, makes the background transparent and save this file in the specified classor. This process might be done specified times in the configuration file.
main.py pulls the specific number of screenshots that specified in the configuration file and background in the specified classor. Places the objects screensshots into the background randomly. Creates an annotations file in json format. Saves the changes.
Data_cleaning.py checks the intersections in the images that generated after execution of blender and main scripts. This control is made by checking the annotations file. Ä°f there is a intersection this code deletes the raws from annotations file, deletes the related images from related classor.
Finally, we have clean, readable image data. There is no process like handling with messy data, because the data is generated by us and no more process for cleaning or handling other problems.
Dataset_splitting.py script divides the dataset into three main branches called as train set, validation set and test set. The size of the sets is specified in the code. 
Json_to_yolo.py script transforms the json format to the yolo format appropriately. 
model_train.py  is a little script to model importing and training.
